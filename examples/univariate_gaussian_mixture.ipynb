{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Gaussian Mixture Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from ebc.sequential.iterative_with_convexification import SensitivityBasedFW\n",
    "from ebc.sequential.iterative_no_convexification import SparseVI\n",
    "\n",
    "from ebc.gaussian import gaussain_univaraite_log_likelihood\n",
    "\n",
    "from splitting import split_based_on_ML, split_based_on_sensitivities, split_randomly, distribute\n",
    "from parallelization import parallelize\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\", category = FutureWarning)\n",
    "\n",
    "import pickle\n",
    "\n",
    "from analyze_distribution import plot_coresets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "full_means = [6, 8, 10]\n",
    "full_sigmas = [0.8, 0.5, 0.2]\n",
    "probs = [0.2, 0.5, 0.3]\n",
    "\n",
    "mixture_inds = np.random.choice([0, 1, 2], size = 5000, replace = True, p = probs)\n",
    "mixture = []\n",
    "\n",
    "for i in mixture_inds:\n",
    "    if i == 0:\n",
    "        mixture.append(np.random.normal(6, 0.8))\n",
    "    if i == 1:\n",
    "        mixture.append(np.random.normal(8, 0.5))\n",
    "    if i == 2:\n",
    "        mixture.append(np.random.normal(10, 0.2))\n",
    "\n",
    "mixture = np.array(mixture).reshape(-1, 1)\n",
    "\n",
    "plt.hist(mixture, bins = 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-likelihood Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params, X, y, weights):\n",
    "    '''\n",
    "    Returns:\n",
    "    ----------\n",
    "    log_lik: np.ndarray(shape = X.shape[0])\n",
    "    '''\n",
    "    probs = params[:3]\n",
    "    mu = params[3:6].reshape(-1, 1)\n",
    "    sigma = params[6:9]\n",
    "\n",
    "    ll = 0\n",
    "    for i in range(3):\n",
    "        ll += probs[i] * gaussain_univaraite_log_likelihood(X, mu[i], sigma[i])\n",
    "    \n",
    "    return ll\n",
    "\n",
    "def summed_log_likelihood(params, X, y, weights):\n",
    "    return log_likelihood(params, X, y, weights).sum()\n",
    "\n",
    "def negative_summed_log_likelihood(params, X, y, weights):\n",
    "    return -summed_log_likelihood(params, X, y, weights)\n",
    "\n",
    "def grad_log_likelihood(params, X, y, weights):\n",
    "    return None\n",
    "\n",
    "def log_posterior(params, X, y, weights):\n",
    "    return weights.T @ log_likelihood(params, X, y, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreset_sizes = np.arange(100, 310, 10)\n",
    "len(coreset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians\n",
    "# https://math.stackexchange.com/questions/2614267/can-we-solve-kl-divergence-between-gaussian-mixtures-by-thinking-conditional-cas\n",
    "def mixture_kl_element(mu0, sigma0, mu1, sigma1, w):\n",
    "    KL = np.log(sigma1 / sigma0) + (sigma0 ** 2 + (mu1 - mu0) ** 2) / (2 * sigma1 ** 2) - 1/2\n",
    "    return KL * w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mixture\n",
    "\n",
    "# Sequential\n",
    "fkl_sequential = []\n",
    "bkl_sequential = []\n",
    "time_sequential = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(9),\n",
    "      \"S\": int(0.3 * 0.7 * len(x)),\n",
    "      \"log_likelihood_gradient\": None,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.7 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(9)}\n",
    "\n",
    "for k in range(20):\n",
    "      try:\n",
    "            np.random.seed(120 + k)\n",
    "            fkl_sequential_k = []\n",
    "            bkl_sequential_k = []\n",
    "            time_sequential_k = []\n",
    "\n",
    "            for i in coreset_sizes:\n",
    "                  print(k, i)\n",
    "                  start = time.time()\n",
    "                  sbfw = SensitivityBasedFW(x)\n",
    "                  w, I = sbfw.run(k = i, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "                  w = (w - np.min(w)) / (np.max(w) - np.min(w))\n",
    "                  time_sequential_k.append(time.time() - start)\n",
    "\n",
    "                  # Calculate posterior approximation\n",
    "                  gm = GaussianMixture(3, n_init = 40)\n",
    "                  gm.fit((w * mixture)[w > 0].reshape(-1, 1))\n",
    "                  means = gm.means_.flatten()\n",
    "                  sigmas = gm.covariances_.flatten()\n",
    "                  ps = gm.weights_.flatten()\n",
    "\n",
    "                  means_inds = np.argsort(means)\n",
    "                  means = means[means_inds]\n",
    "                  sigmas = sigmas[means_inds]\n",
    "                  ps = ps[means_inds]\n",
    "\n",
    "                  fkl = 0\n",
    "                  bkl = 0\n",
    "                  for j in range(3):\n",
    "                        fkl += mixture_kl_element(full_means[j], full_sigmas[j], means[j], sigmas[j], ps[j])\n",
    "                        bkl += mixture_kl_element(means[j], sigmas[j], full_means[j], full_sigmas[j], ps[j])\n",
    "\n",
    "                  fkl_sequential_k.append(fkl)\n",
    "                  bkl_sequential_k.append(bkl)\n",
    "\n",
    "            fkl_sequential.append(fkl_sequential_k)\n",
    "            bkl_sequential.append(bkl_sequential_k)\n",
    "            time_sequential.append(time_sequential_k)\n",
    "      except:\n",
    "            continue\n",
    "\n",
    "print(f\"FKL: {fkl_sequential}\")\n",
    "print(f\"BKL: {bkl_sequential}\")\n",
    "print(f\"Time: {time_sequential}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkl_sequential = np.array(fkl_sequential)\n",
    "bkl_sequential = np.array(bkl_sequential)\n",
    "time_sequential = np.array(time_sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mixture\n",
    "\n",
    "# Parallel\n",
    "fkl_parallel = []\n",
    "bkl_parallel = []\n",
    "time_parallel = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(9),\n",
    "      \"S\": int(0.3 * 0.1 * len(x)),\n",
    "      \"log_likelihood_gradient\": None,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.1 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(9)}\n",
    "\n",
    "for k in range(20):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_parallel_k = []\n",
    "      bkl_parallel_k = []\n",
    "      time_parallel_k = []\n",
    "\n",
    "      for i in coreset_sizes:\n",
    "            print(f\"{k}: {i}\")\n",
    "            fkl_parallel_i = []\n",
    "            bkl_parallel_i = []\n",
    "            time_parallel_i = []\n",
    "            for ind, strat in enumerate([split_randomly, split_based_on_ML]):\n",
    "                  start = time.time()\n",
    "\n",
    "                  # Step 1: distribute\n",
    "                  if ind == 0:\n",
    "                        full_inds = strat(x)\n",
    "                  elif ind == 1:\n",
    "                        gm = GaussianMixture(3, n_init = 40)\n",
    "                        gm.fit(mixture)\n",
    "                        # Get probability estimates\n",
    "                        params = np.hstack((gm.weights_.flatten(), gm.means_.flatten(), gm.covariances_.flatten()))\n",
    "                        log_liks = log_likelihood(params, mixture, None, None)\n",
    "                        probs = np.abs(log_liks) / np.sum(np.abs(log_liks))\n",
    "                        probs = probs.flatten()\n",
    "                        full_inds = distribute(probs)\n",
    "\n",
    "                  # Step 2: run\n",
    "                  w, _ = parallelize(alg = SensitivityBasedFW, x = x, k = int(i // mp.cpu_count()), norm = \"2\", na = na, distributed_indices = full_inds)\n",
    "                  w = (w - np.min(w)) / (np.max(w) - np.min(w))\n",
    "\n",
    "                  time_parallel_i.append(time.time() - start)\n",
    "\n",
    "                  # Calculate posterior approximation\n",
    "                  gm = GaussianMixture(3, n_init = 40)\n",
    "                  gm.fit((w * mixture)[w > 0].reshape(-1, 1))\n",
    "                  means = gm.means_.flatten()\n",
    "                  sigmas = gm.covariances_.flatten()\n",
    "                  ps = gm.weights_.flatten()\n",
    "\n",
    "                  means_inds = np.argsort(means)\n",
    "                  means = means[means_inds]\n",
    "                  sigmas = sigmas[means_inds]\n",
    "                  ps = ps[means_inds]\n",
    "\n",
    "                  fkl = 0\n",
    "                  bkl = 0\n",
    "                  for j in range(3):\n",
    "                        fkl += mixture_kl_element(full_means[j], full_sigmas[j], means[j], sigmas[j], ps[j])\n",
    "                        bkl += mixture_kl_element(means[j], sigmas[j], full_means[j], full_sigmas[j], ps[j])\n",
    "\n",
    "                  fkl_parallel_i.append(fkl)\n",
    "                  bkl_parallel_i.append(bkl)\n",
    "\n",
    "            fkl_parallel_k.append(fkl_parallel_i)\n",
    "            bkl_parallel_k.append(bkl_parallel_i)\n",
    "            time_parallel_k.append(time_parallel_i)\n",
    "\n",
    "      fkl_parallel.append(fkl_parallel_k)\n",
    "      bkl_parallel.append(bkl_parallel_k)\n",
    "      time_parallel.append(time_parallel_k)\n",
    "\n",
    "print(f\"FKL: {fkl_parallel}\")\n",
    "print(f\"BKL: {bkl_parallel}\")\n",
    "print(f\"Time: {time_parallel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkl_parallel = np.array(fkl_parallel)\n",
    "bkl_parallel = np.array(bkl_parallel)\n",
    "time_parallel = np.array(time_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"fkl_sequential\": fkl_sequential,\n",
    "    \"bkl_sequential\": bkl_sequential,\n",
    "    \"time_sequential\": time_sequential,\n",
    "    \"fkl_parallel\": fkl_parallel,\n",
    "    \"bkl_parallel\": bkl_parallel,\n",
    "    \"time_parallel\": time_parallel\n",
    "}\n",
    "\n",
    "with open('../data/univariate_gaussian_mixture.pickle', 'wb') as file:\n",
    "    pickle.dump(data, file, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/univariate_gaussian_mixture.pickle\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "fkl_sequential = data[\"fkl_sequential\"]\n",
    "bkl_sequential = data[\"bkl_sequential\"]\n",
    "time_sequential = data[\"time_sequential\"]\n",
    "fkl_parallel = data[\"fkl_parallel\"]\n",
    "bkl_parallel = data[\"bkl_parallel\"]\n",
    "time_parallel = data[\"time_parallel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klsym_sequential = (fkl_sequential + bkl_sequential) / 2\n",
    "klsym_parallel = (fkl_parallel + bkl_parallel) / 2\n",
    "\n",
    "coreset_sizes = np.arange(100, 310, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "fig = plt.figure(figsize = (20, 7))\n",
    "\n",
    "ax11 = fig.add_subplot(221)\n",
    "ax12 = fig.add_subplot(223)\n",
    "\n",
    "ax13 = fig.add_subplot(222)\n",
    "ax14 = fig.add_subplot(224, sharex = ax13)\n",
    "\n",
    "ax11.plot(coreset_sizes, np.log(np.nanmedian(klsym_sequential, axis = 0)), label = 'Sequential', \n",
    "          linestyle = \"solid\", linewidth = 2, color = 'black')\n",
    "ax12.plot(coreset_sizes, np.log(np.nanmedian(klsym_parallel, axis = 0)[:, 0]), label = 'Random split',\n",
    "          linestyle = \"dashed\", linewidth = 2, color = 'dimgray')\n",
    "ax12.plot(coreset_sizes, np.log(np.nanmedian(klsym_parallel, axis = 0)[:, 1]), label = 'ML split',\n",
    "          linestyle = \"solid\", marker = \"o\", linewidth = 2, color = 'maroon')\n",
    "\n",
    "ax11.spines['bottom'].set_visible(False)\n",
    "ax11.xaxis.tick_top()\n",
    "ax11.tick_params(labeltop = False)\n",
    "ax12.spines['top'].set_visible(False)\n",
    "ax12.ticklabel_format(useOffset=False)\n",
    "\n",
    "ax13.spines['bottom'].set_visible(False)\n",
    "ax13.xaxis.tick_top()\n",
    "ax13.tick_params(labeltop = False)\n",
    "ax14.spines['top'].set_visible(False)\n",
    "ax14.ticklabel_format(useOffset=False)\n",
    "\n",
    "ax12.set_xlabel(\"Coreset size\")\n",
    "ax14.set_xlabel(\"Coreset size\")\n",
    "\n",
    "fig.text(0.04, 0.5, 'Log KL', va='center', rotation='vertical')\n",
    "fig.text(0.494, 0.5, 'Seconds', va='center', rotation='vertical')\n",
    "\n",
    "d = .015\n",
    "kwargs = dict(transform=ax11.transAxes, color='k', clip_on=False)\n",
    "ax11.plot((-d, +d), (-d, +d), **kwargs)\n",
    "ax11.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=ax12.transAxes)\n",
    "ax12.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "ax12.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "kwargs = dict(transform=ax13.transAxes, color='k', clip_on=False)\n",
    "ax13.plot((-d, +d), (-d, +d), **kwargs)\n",
    "ax13.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=ax14.transAxes)\n",
    "ax14.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "ax14.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "fig.legend()\n",
    "fig.suptitle('Univariate Gaussian Mixture')\n",
    "\n",
    "ax13.plot(coreset_sizes, np.median(time_sequential, axis = 0), label = 'Sequential',\n",
    "          linestyle = \"solid\", linewidth = 2, color = 'black')\n",
    "ax14.plot(coreset_sizes, np.median(time_parallel, axis = 0)[:, 0], label = 'Random split',\n",
    "          linestyle = \"dashed\", linewidth = 2, color = 'dimgray')\n",
    "ax14.plot(coreset_sizes, np.median(time_parallel, axis = 0)[:, 1], label = 'ML split',\n",
    "          linestyle = \"solid\", marker = \"o\", linewidth = 2, color = 'maroon')\n",
    "\n",
    "ax11.grid()\n",
    "ax12.grid()\n",
    "ax13.grid()\n",
    "ax14.grid()\n",
    "\n",
    "plt.savefig(\"../plots/univariate_gaussian_mixture.eps\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
