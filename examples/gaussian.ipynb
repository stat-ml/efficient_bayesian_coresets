{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Gaussian Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from ebc.sequential.iterative_with_convexification import SensitivityBasedFW\n",
    "from ebc.gaussian import gaussian_multivariate_log_likelihood, gaussian_KL\n",
    "\n",
    "from splitting import split_based_on_ML, split_randomly, distribute\n",
    "from parallelization import parallelize\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pickle\n",
    "\n",
    "from analyze_distribution import plot_coresets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-likelihoods Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log-likelihood\n",
    "\n",
    "def log_likelihood(params, X, y, weights):\n",
    "    '''\n",
    "    Returns:\n",
    "    ----------\n",
    "    log_lik: np.ndarray(shape = X.shape[0])\n",
    "    '''\n",
    "    d = X.shape[1]\n",
    "    mu = params[:d].reshape(-1, 1)\n",
    "    sigma = np.diag(params[d:].reshape(-1, 1)[:, 0])\n",
    "    return np.diag(gaussian_multivariate_log_likelihood(X.T, mu, sigma)).reshape(-1, 1)\n",
    "\n",
    "def summed_log_likelihood(params, X, y, weights):\n",
    "    return log_likelihood(params, X, y, weights).sum()\n",
    "\n",
    "def negative_summed_log_likelihood(params, X, y, weights):\n",
    "    return -summed_log_likelihood(params, X, y, weights)\n",
    "\n",
    "# https://stats.stackexchange.com/questions/90134/gradient-of-multivariate-gaussian-log-likelihood\n",
    "def grad_log_likelihood(params, X, y, weights):\n",
    "    '''\n",
    "    Returns:\n",
    "    ----------\n",
    "    grad_log_lik: np.ndarray(shape = X.shape[1])\n",
    "    '''\n",
    "    d = X.shape[1]\n",
    "    mu = params[:d].reshape(-1, 1)\n",
    "    sigma = np.diag(params[d:].reshape(-1, 1)[:, 0])\n",
    "    return (-np.linalg.inv(sigma) @ (X.T - mu)).reshape(-1, X.shape[1])\n",
    "\n",
    "def log_posterior(params, X, y, weights):\n",
    "    return weights.T @ log_likelihood(params, X, y, weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "N = 5000\n",
    "d = 5\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generate mean from MVN\n",
    "theta = np.random.multivariate_normal(mean = np.zeros(d), cov = np.identity(d))\n",
    "\n",
    "# Generate data\n",
    "x = np.random.multivariate_normal(mean = theta, cov = np.identity(d), size = N)\n",
    "\n",
    "# Parameters\n",
    "sigma_0 = np.identity(d)\n",
    "sigma = np.identity(d)\n",
    "mu_0 = np.zeros(d).reshape(-1, 1)\n",
    "\n",
    "# Full Gaussian posterior\n",
    "sigma_full = np.linalg.inv(np.linalg.inv(sigma_0) + N * np.linalg.inv(sigma))\n",
    "mu_full =  sigma_full @ (np.linalg.inv(sigma_0) @ mu_0 + np.linalg.inv(sigma) @ np.sum(x, axis = 0).reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreset_sizes = np.arange(100, 310, 10)\n",
    "len(coreset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential\n",
    "fkl_sequential = []\n",
    "bkl_sequential = []\n",
    "time_sequential = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(2 * d),\n",
    "      \"S\": 100,\n",
    "      \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.7 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(2 * d)}\n",
    "\n",
    "for k in range(20):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_sequential_k = []\n",
    "      bkl_sequential_k = []\n",
    "      time_sequential_k = []\n",
    "\n",
    "      w_seq = []\n",
    "\n",
    "      for i in coreset_sizes:\n",
    "            print(i, k)\n",
    "            start = time.time()\n",
    "            sbfw = SensitivityBasedFW(x)\n",
    "            w, I = sbfw.run(k = i, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "            time_sequential_k.append(time.time() - start)\n",
    "\n",
    "            # Calculate posterior approximation\n",
    "            sigma_hat = 1 / (1 + np.sum(w)) * np.identity(d)\n",
    "            mu_hat = sigma_hat @ (mu_0 + x.T @ w)\n",
    "\n",
    "            fkl_sequential_k.append(gaussian_KL(sigma_full, sigma_hat, mu_full, mu_hat))\n",
    "            bkl_sequential_k.append(gaussian_KL(sigma_hat, sigma_full, mu_hat, mu_full))\n",
    "\n",
    "            w_seq.append(w)\n",
    "\n",
    "      fkl_sequential.append(fkl_sequential_k)\n",
    "      bkl_sequential.append(bkl_sequential_k)\n",
    "      time_sequential.append(time_sequential_k)\n",
    "\n",
    "print(f\"FKL: {fkl_sequential}\")\n",
    "print(f\"BKL: {bkl_sequential}\")\n",
    "print(f\"Time: {time_sequential}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkl_sequential = np.array(fkl_sequential)\n",
    "bkl_sequential = np.array(bkl_sequential)\n",
    "time_sequential = np.array(time_sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel\n",
    "fkl_parallel = []\n",
    "bkl_parallel = []\n",
    "time_parallel = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(2 * d),\n",
    "      \"S\": 100,\n",
    "      \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.1 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(2 * d)}\n",
    "\n",
    "for k in range(20):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_parallel_k = []\n",
    "      bkl_parallel_k = []\n",
    "      time_parallel_k = []\n",
    "\n",
    "      full_inds_i = []\n",
    "      output_i = []\n",
    "      w_i = []\n",
    "\n",
    "      for i in coreset_sizes:\n",
    "            print(k, i)\n",
    "            fkl_parallel_i = []\n",
    "            bkl_parallel_i = []\n",
    "            time_parallel_i = []\n",
    "            for ind, strat in enumerate([split_randomly, split_based_on_ML]):\n",
    "                  start = time.time()\n",
    "\n",
    "                  # Step 1: distribute\n",
    "                  if ind == 0:\n",
    "                        full_inds = strat(x)\n",
    "                  elif ind == 1:\n",
    "                        gm = GaussianMixture(1)\n",
    "                        gm.fit(x)\n",
    "                        params = np.hstack((gm.means_.flatten(), np.diag(gm.covariances_[0])))\n",
    "                        log_liks = log_likelihood(params, x, None, None)\n",
    "                        probs = np.abs(log_liks) / np.sum(np.abs(log_liks))\n",
    "                        probs = probs.flatten()\n",
    "                        full_inds = distribute(probs)\n",
    "\n",
    "                  full_inds_i.append(full_inds)\n",
    "\n",
    "                  # Step 2: run\n",
    "                  w, output = parallelize(alg = SensitivityBasedFW, x = x, k = int(i // mp.cpu_count()), norm = \"2\", na = na, distributed_indices = full_inds)\n",
    "\n",
    "                  time_parallel_i.append(time.time() - start)\n",
    "\n",
    "                  # Calculate posterior approximation\n",
    "                  sigma_hat = 1 / (1 + np.sum(w)) * np.identity(d)\n",
    "                  mu_hat = sigma_hat @ (mu_0 + x.T @ w)\n",
    "\n",
    "                  fkl_parallel_i.append(gaussian_KL(sigma_full, sigma_hat, mu_full, mu_hat))\n",
    "                  bkl_parallel_i.append(gaussian_KL(sigma_hat, sigma_full, mu_hat, mu_full))\n",
    "\n",
    "                  output_i.append(output)\n",
    "                  w_i.append(w)\n",
    "\n",
    "            fkl_parallel_k.append(fkl_parallel_i)\n",
    "            bkl_parallel_k.append(bkl_parallel_i)\n",
    "            time_parallel_k.append(time_parallel_i)\n",
    "\n",
    "      fkl_parallel.append(fkl_parallel_k)\n",
    "      bkl_parallel.append(bkl_parallel_k)\n",
    "      time_parallel.append(time_parallel_k)\n",
    "\n",
    "print(f\"FKL: {fkl_parallel}\")\n",
    "print(f\"BKL: {bkl_parallel}\")\n",
    "print(f\"Time: {time_parallel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkl_parallel = np.array(fkl_parallel)\n",
    "bkl_parallel = np.array(bkl_parallel)\n",
    "time_parallel = np.array(time_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"fkl_sequential\": fkl_sequential,\n",
    "    \"bkl_sequential\": bkl_sequential,\n",
    "    \"time_sequential\": time_sequential,\n",
    "    \"fkl_parallel\": fkl_parallel,\n",
    "    \"bkl_parallel\": bkl_parallel,\n",
    "    \"time_parallel\": time_parallel\n",
    "}\n",
    "\n",
    "with open('../data/gaussian.pickle', 'wb') as file:\n",
    "    pickle.dump(data, file, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/gaussian.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "fkl_sequential = np.array(data['fkl_sequential'])\n",
    "bkl_sequential = np.array(data['bkl_sequential'])\n",
    "time_sequential = np.array(data['time_sequential'])\n",
    "fkl_parallel = np.array(data['fkl_parallel'])\n",
    "bkl_parallel = np.array(data['bkl_parallel'])\n",
    "time_parallel = np.array(data['time_parallel'])\n",
    "\n",
    "coreset_sizes = np.arange(100, 310, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klsym_sequential = (fkl_sequential + bkl_sequential) / 2\n",
    "klsym_parallel = (fkl_parallel + bkl_parallel) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "fig = plt.figure(figsize = (20, 7))\n",
    "\n",
    "ax12 = fig.add_subplot(121)\n",
    "ax13 = fig.add_subplot(222)\n",
    "ax14 = fig.add_subplot(224, sharex = ax13)\n",
    "\n",
    "ax12.plot(coreset_sizes, np.log(np.median(klsym_sequential, axis = 0)), label = 'Sequential', \n",
    "          linestyle = \"solid\", linewidth = 2, color = 'black')\n",
    "ax12.plot(coreset_sizes, np.log(np.median(klsym_parallel, axis = 0)[:, 0]), label = 'Random split',\n",
    "          linestyle = \"dashed\", linewidth = 2, color = 'dimgray')\n",
    "ax12.plot(coreset_sizes, np.log(np.median(klsym_parallel, axis = 0)[:, 1]), label = 'ML split',\n",
    "          linestyle = \"solid\", marker = \"o\", linewidth = 2, color = 'maroon')\n",
    "\n",
    "ax13.spines['bottom'].set_visible(False)\n",
    "ax13.xaxis.tick_top()\n",
    "ax13.tick_params(labeltop = False)\n",
    "ax14.spines['top'].set_visible(False)\n",
    "ax14.ticklabel_format(useOffset=False)\n",
    "\n",
    "ax12.set_xlabel(\"Coreset size\")\n",
    "ax14.set_xlabel(\"Coreset size\")\n",
    "fig.text(0.07, 0.5, 'Log KL', va = 'center', rotation = 'vertical')\n",
    "fig.text(0.5, 0.5, 'Seconds', va = 'center', rotation = 'vertical')\n",
    "\n",
    "d = .015\n",
    "kwargs = dict(transform = ax13.transAxes, color = 'k', clip_on = False)\n",
    "ax13.plot((-d, +d), (-d, +d), **kwargs)\n",
    "ax13.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "\n",
    "kwargs.update(transform = ax14.transAxes)\n",
    "ax14.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "ax14.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "fig.legend()\n",
    "fig.suptitle('Multivariate Gaussian')\n",
    "\n",
    "ax13.plot(coreset_sizes, np.median(time_sequential, axis = 0), label = 'Sequential',\n",
    "          linestyle = \"solid\", linewidth = 2, color = 'black')\n",
    "ax14.plot(coreset_sizes, np.median(time_parallel, axis = 0)[:, 0], label = 'Random split',\n",
    "          linestyle = \"dashed\", linewidth = 2, color = 'dimgray')\n",
    "ax14.plot(coreset_sizes, np.median(time_parallel, axis = 0)[:, 1], label = 'ML split',\n",
    "          linestyle = \"solid\", marker = \"o\", linewidth = 2, color = 'maroon')\n",
    "\n",
    "ax12.grid()\n",
    "ax13.grid()\n",
    "ax14.grid()\n",
    "\n",
    "plt.savefig(\"../plots/gaussian.eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "N = 500\n",
    "d = 2\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generate mean from MVN\n",
    "theta = np.random.multivariate_normal(mean = np.zeros(d), cov = np.identity(d))\n",
    "\n",
    "# Generate data\n",
    "x = np.random.multivariate_normal(mean = theta, cov = np.identity(d), size = N)\n",
    "\n",
    "# Parameters\n",
    "sigma_0 = np.identity(d)\n",
    "sigma = np.identity(d)\n",
    "mu_0 = np.zeros(d).reshape(-1, 1)\n",
    "\n",
    "# Full Gaussian posterior\n",
    "sigma_full = np.linalg.inv(np.linalg.inv(sigma_0) + N * np.linalg.inv(sigma))\n",
    "mu_full =  sigma_full @ (np.linalg.inv(sigma_0) @ mu_0 + np.linalg.inv(sigma) @ np.sum(x, axis = 0).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential\n",
    "fkl_sequential = []\n",
    "bkl_sequential = []\n",
    "time_sequential = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(2 * d),\n",
    "      \"S\": 100,\n",
    "      \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.7 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(2 * d)}\n",
    "\n",
    "for k in range(1):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_sequential_k = []\n",
    "      bkl_sequential_k = []\n",
    "      time_sequential_k = []\n",
    "\n",
    "      w_seq = []\n",
    "\n",
    "      for i in [100, 200, 300]:\n",
    "            print(i, k)\n",
    "            start = time.time()\n",
    "            sbfw = SensitivityBasedFW(x)\n",
    "            w, I = sbfw.run(k = i, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "            time_sequential_k.append(time.time() - start)\n",
    "\n",
    "            # Calculate posterior approximation\n",
    "            sigma_hat = 1 / (1 + np.sum(w)) * np.identity(d)\n",
    "            mu_hat = sigma_hat @ (mu_0 + x.T @ w)\n",
    "\n",
    "            fkl_sequential_k.append(gaussian_KL(sigma_full, sigma_hat, mu_full, mu_hat))\n",
    "            bkl_sequential_k.append(gaussian_KL(sigma_hat, sigma_full, mu_hat, mu_full))\n",
    "\n",
    "            w_seq.append(w)\n",
    "\n",
    "      fkl_sequential.append(fkl_sequential_k)\n",
    "      bkl_sequential.append(bkl_sequential_k)\n",
    "      time_sequential.append(time_sequential_k)\n",
    "\n",
    "print(f\"FKL: {fkl_sequential}\")\n",
    "print(f\"BKL: {bkl_sequential}\")\n",
    "print(f\"Time: {time_sequential}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel\n",
    "fkl_parallel = []\n",
    "bkl_parallel = []\n",
    "time_parallel = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(2 * d),\n",
    "      \"S\": 100,\n",
    "      \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.1 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(2 * d)}\n",
    "\n",
    "for k in range(1):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_parallel_k = []\n",
    "      bkl_parallel_k = []\n",
    "      time_parallel_k = []\n",
    "\n",
    "      full_inds_i = []\n",
    "      output_i = []\n",
    "      w_i = []\n",
    "\n",
    "      for i in [100, 200, 300]:\n",
    "            print(k, i)\n",
    "            fkl_parallel_i = []\n",
    "            bkl_parallel_i = []\n",
    "            time_parallel_i = []\n",
    "            for ind, strat in enumerate([split_randomly, split_based_on_ML]):\n",
    "                  start = time.time()\n",
    "\n",
    "                  # Step 1: distribute\n",
    "                  if ind == 0:\n",
    "                        full_inds = strat(x)\n",
    "                  elif ind == 1:\n",
    "                        gm = GaussianMixture(1)\n",
    "                        gm.fit(x)\n",
    "                        params = np.hstack((gm.means_.flatten(), np.diag(gm.covariances_[0])))\n",
    "                        log_liks = log_likelihood(params, x, None, None)\n",
    "                        probs = np.abs(log_liks) / np.sum(np.abs(log_liks))\n",
    "                        probs = probs.flatten()\n",
    "                        full_inds = distribute(probs)\n",
    "\n",
    "                  full_inds_i.append(full_inds)\n",
    "\n",
    "                  # Step 2: run\n",
    "                  w, output = parallelize(alg = SensitivityBasedFW, x = x, k = int(i // mp.cpu_count()), norm = \"2\", na = na, distributed_indices = full_inds)\n",
    "\n",
    "                  time_parallel_i.append(time.time() - start)\n",
    "\n",
    "                  # Calculate posterior approximation\n",
    "                  sigma_hat = 1 / (1 + np.sum(w)) * np.identity(d)\n",
    "                  mu_hat = sigma_hat @ (mu_0 + x.T @ w)\n",
    "\n",
    "                  fkl_parallel_i.append(gaussian_KL(sigma_full, sigma_hat, mu_full, mu_hat))\n",
    "                  bkl_parallel_i.append(gaussian_KL(sigma_hat, sigma_full, mu_hat, mu_full))\n",
    "\n",
    "                  output_i.append(output)\n",
    "                  w_i.append(w)\n",
    "\n",
    "            fkl_parallel_k.append(fkl_parallel_i)\n",
    "            bkl_parallel_k.append(bkl_parallel_i)\n",
    "            time_parallel_k.append(time_parallel_i)\n",
    "\n",
    "      fkl_parallel.append(fkl_parallel_k)\n",
    "      bkl_parallel.append(bkl_parallel_k)\n",
    "      time_parallel.append(time_parallel_k)\n",
    "\n",
    "print(f\"FKL: {fkl_parallel}\")\n",
    "print(f\"BKL: {bkl_parallel}\")\n",
    "print(f\"Time: {time_parallel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coresets(x, w_seq[0], full_inds_i[0], output_i[0], w_i[0], 100, \"gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coresets(x, w_seq[1], full_inds_i[1], output_i[1], w_i[1], 200, \"gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coresets(x, w_seq[2], full_inds_i[2], output_i[2], w_i[2], 300, \"gaussian\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
