{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Gaussian Mixture Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "from ebc.sequential.iterative_with_convexification import SensitivityBasedFW\n",
    "\n",
    "from ebc.gaussian import gaussian_multivariate_log_likelihood, gaussian_KL\n",
    "\n",
    "from splitting import split_based_on_ML, split_based_on_sensitivities, split_randomly, distribute\n",
    "from parallelization import parallelize\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\", category = FutureWarning)\n",
    "\n",
    "import pickle\n",
    "\n",
    "from analyze_distribution import plot_coresets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "mu0 = np.array([0, 0]).reshape((-1, 1))\n",
    "mu1 = np.array([-1, 1]).reshape((-1, 1))\n",
    "sigma0 = np.array([[1, 0.9,],\n",
    "                   [0.9, 1]])\n",
    "sigma1 = np.array([[1, -0.9,],\n",
    "                   [-0.9, 1]])\n",
    "\n",
    "full_means = [mu0, mu1]\n",
    "full_sigmas = [sigma0, sigma1]\n",
    "\n",
    "mixture_inds = np.random.choice([0, 1], size = 3000, replace = True)\n",
    "mixture = []\n",
    "\n",
    "for i in mixture_inds:\n",
    "    if i == 0:\n",
    "        mixture.append(np.random.multivariate_normal(mu0.flatten(), sigma0))\n",
    "    if i == 1:\n",
    "       mixture.append(np.random.multivariate_normal(mu1.flatten(), sigma1))\n",
    "\n",
    "mixture = np.array(mixture).reshape(-1, 2)\n",
    "\n",
    "plt.scatter(mixture[:, 0], mixture[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(2)\n",
    "cl = km.fit_predict(mixture)\n",
    "plt.scatter(mixture[:, 0], mixture[:, 1], c = cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(2)\n",
    "gm.fit(mixture)\n",
    "cl = gm.fit_predict(mixture)\n",
    "plt.scatter(mixture[:, 0], mixture[:, 1], c = cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-likelihood Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log-likelihood\n",
    "\n",
    "def log_likelihood(params, X, y, weights):\n",
    "    '''\n",
    "    Returns:\n",
    "    ----------\n",
    "    log_lik: np.ndarray(shape = X.shape[0])\n",
    "    '''\n",
    "    probs = params[0]\n",
    "    mu0 = params[1:3].reshape(-1, 1)\n",
    "    mu1 = params[3:5].reshape(-1, 1)\n",
    " \n",
    "    ll =  probs * np.diag(gaussian_multivariate_log_likelihood(X.T, mu0, sigma0)).reshape(-1, 1) +\\\n",
    "          (1 - probs) * np.diag(gaussian_multivariate_log_likelihood(X.T, mu1, sigma1)).reshape(-1, 1)\n",
    "    \n",
    "    return ll\n",
    "\n",
    "def summed_log_likelihood(params, X, y, weights):\n",
    "    return log_likelihood(params, X, y, weights).sum()\n",
    "\n",
    "def negative_summed_log_likelihood(params, X, y, weights):\n",
    "    return -summed_log_likelihood(params, X, y, weights)\n",
    "\n",
    "# https://stats.stackexchange.com/questions/90134/gradient-of-multivariate-gaussian-log-likelihood\n",
    "def grad_log_likelihood(params, X, y, weights):\n",
    "    '''\n",
    "    Returns:\n",
    "    ----------\n",
    "    grad_log_lik: np.ndarray(shape = X.shape[1])\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def log_posterior(params, X, y, weights):\n",
    "    return weights.T @ log_likelihood(params, X, y, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreset_sizes = np.arange(100, 310, 10)\n",
    "len(coreset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians\n",
    "# https://math.stackexchange.com/questions/2614267/can-we-solve-kl-divergence-between-gaussian-mixtures-by-thinking-conditional-cas\n",
    "def mixture_kl_element(mu0, sigma0, mu1, sigma1, w):\n",
    "    return w * gaussian_KL(sigma0, sigma1, mu0, mu1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mixture\n",
    "\n",
    "# Sequential\n",
    "fkl_sequential = []\n",
    "bkl_sequential = []\n",
    "time_sequential = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(9),\n",
    "      \"S\": int(0.3 * len(x)),\n",
    "      \"log_likelihood_gradient\": None,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.7 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(9)}\n",
    "\n",
    "for k in range(10):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_sequential_k = []\n",
    "      bkl_sequential_k = []\n",
    "      time_sequential_k = []\n",
    "\n",
    "      for i in coreset_sizes:\n",
    "            print(k, i)\n",
    "            start = time.time()\n",
    "            sbfw = SensitivityBasedFW(x)\n",
    "            w, I = sbfw.run(k = i, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "            time_sequential_k.append(time.time() - start)\n",
    "\n",
    "            # Calculate posterior approximation\n",
    "            gm = GaussianMixture(2)\n",
    "            gm.fit((w * mixture)[w.flatten() > 0])\n",
    "            means = gm.means_\n",
    "            sigmas = gm.covariances_\n",
    "            ps = gm.weights_\n",
    "\n",
    "            means_inds = np.argsort(np.linalg.norm(means, axis = 1))\n",
    "            means = means[means_inds]\n",
    "            sigmas = sigmas[means_inds]\n",
    "            ps = ps[means_inds]\n",
    "\n",
    "            fkl = 0\n",
    "            bkl = 0\n",
    "            for j in range(2):\n",
    "                  fkl += mixture_kl_element(full_means[j], full_sigmas[j], means[:, j], sigmas[j], ps[j])\n",
    "                  bkl += mixture_kl_element(means[:, j], sigmas[j], full_means[j], full_sigmas[j], ps[j])\n",
    "\n",
    "            fkl_sequential_k.append(fkl)\n",
    "            bkl_sequential_k.append(bkl)\n",
    "\n",
    "      fkl_sequential.append(fkl_sequential_k)\n",
    "      bkl_sequential.append(bkl_sequential_k)\n",
    "      time_sequential.append(time_sequential_k)\n",
    "\n",
    "print(f\"FKL: {fkl_sequential}\")\n",
    "print(f\"BKL: {bkl_sequential}\")\n",
    "print(f\"Time: {time_sequential}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkl_sequential = np.array(fkl_sequential)\n",
    "bkl_sequential = np.array(bkl_sequential)\n",
    "time_sequential = np.array(time_sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mixture\n",
    "\n",
    "# Parallel\n",
    "fkl_parallel = []\n",
    "bkl_parallel = []\n",
    "time_parallel = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(9),\n",
    "      \"S\": int(0.3 * 0.1 * len(x)),\n",
    "      \"log_likelihood_gradient\": None,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.1 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(9)}\n",
    "\n",
    "for k in range(10):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_parallel_k = []\n",
    "      bkl_parallel_k = []\n",
    "      time_parallel_k = []\n",
    "\n",
    "      for i in coreset_sizes:\n",
    "            print(f\"{k}: {i}\")\n",
    "            fkl_parallel_i = []\n",
    "            bkl_parallel_i = []\n",
    "            time_parallel_i = []\n",
    "            for ind, strat in enumerate([split_randomly, split_based_on_ML]):\n",
    "                  start = time.time()\n",
    "\n",
    "                  # Step 1: distribute\n",
    "                  if ind == 0:\n",
    "                        full_inds = strat(x)\n",
    "                  elif ind == 1:\n",
    "                        gm = GaussianMixture(2, n_init = 40)\n",
    "                        gm.fit(mixture)\n",
    "                        \n",
    "                        # Get probability estimates\n",
    "                        params = np.hstack((gm.weights_.flatten()[0], gm.means_.flatten()))\n",
    "                        log_liks = log_likelihood(params, mixture, None, None)\n",
    "                        probs = np.abs(log_liks) / np.sum(np.abs(log_liks))\n",
    "                        probs = probs.flatten()\n",
    "                        full_inds = distribute(probs)\n",
    "\n",
    "                  # Step 2: run\n",
    "                  w, output = parallelize(alg = SensitivityBasedFW, x = mixture, k = int(i // mp.cpu_count()), norm = \"2\", na = na, distributed_indices = full_inds)\n",
    "\n",
    "                  time_parallel_i.append(time.time() - start)\n",
    "\n",
    "                  # Calculate posterior approximation\n",
    "                  gm = GaussianMixture(2, n_init = 40)\n",
    "                  gm.fit((w * mixture)[w.flatten() > 0])\n",
    "                  means = gm.means_\n",
    "                  sigmas = gm.covariances_\n",
    "                  ps = gm.weights_\n",
    "\n",
    "                  means_inds = np.argsort(np.linalg.norm(means, axis = 1))\n",
    "                  means = means[means_inds]\n",
    "                  sigmas = sigmas[means_inds]\n",
    "                  ps = ps[means_inds]\n",
    "\n",
    "                  fkl = 0\n",
    "                  bkl = 0\n",
    "                  for j in range(2):\n",
    "                        fkl += mixture_kl_element(full_means[j], full_sigmas[j], means[j, :], sigmas[j], ps[j])\n",
    "                        bkl += mixture_kl_element(means[j, :], sigmas[j], full_means[j], full_sigmas[j], ps[j])\n",
    "\n",
    "                  fkl_parallel_i.append(fkl)\n",
    "                  bkl_parallel_i.append(bkl)\n",
    "\n",
    "            fkl_parallel_k.append(fkl_parallel_i)\n",
    "            bkl_parallel_k.append(bkl_parallel_i)\n",
    "            time_parallel_k.append(time_parallel_i)\n",
    "\n",
    "      fkl_parallel.append(fkl_parallel_k)\n",
    "      bkl_parallel.append(bkl_parallel_k)\n",
    "      time_parallel.append(time_parallel_k)\n",
    "\n",
    "print(f\"FKL: {fkl_parallel}\")\n",
    "print(f\"BKL: {bkl_parallel}\")\n",
    "print(f\"Time: {time_parallel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkl_parallel = np.array(fkl_parallel)\n",
    "bkl_parallel = np.array(bkl_parallel)\n",
    "time_parallel = np.array(time_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"fkl_sequential\": fkl_sequential,\n",
    "    \"bkl_sequential\": bkl_sequential,\n",
    "    \"time_sequential\": time_sequential,\n",
    "    \"fkl_parallel\": fkl_parallel,\n",
    "    \"bkl_parallel\": bkl_parallel,\n",
    "    \"time_parallel\": time_parallel\n",
    "}\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('../data/multivariate_gaussian_mixture.pickle', 'wb') as file:\n",
    "    pickle.dump(data, file, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/multivariate_gaussian_mixture.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "fkl_sequential = np.array(data['fkl_sequential'])\n",
    "bkl_sequential = np.array(data['bkl_sequential'])\n",
    "time_sequential = np.array(data['time_sequential'])\n",
    "fkl_parallel = np.array(data['fkl_parallel'])\n",
    "bkl_parallel = np.array(data['bkl_parallel'])\n",
    "time_parallel = np.array(data['time_parallel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klsym_sequential = (fkl_sequential + bkl_sequential) / 2\n",
    "klsym_parallel = (fkl_parallel + bkl_parallel) / 2\n",
    "\n",
    "coreset_sizes = np.arange(100, 310, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(np.nanmedian(klsym_sequential, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "fig = plt.figure(figsize = (20, 7))\n",
    "\n",
    "ax12 = fig.add_subplot(121)\n",
    "\n",
    "ax13 = fig.add_subplot(222)\n",
    "ax14 = fig.add_subplot(224, sharex = ax13)\n",
    "\n",
    "ax12.plot(coreset_sizes, np.log(np.nanmedian(klsym_sequential, axis = 0)), label = 'Sequential', \n",
    "           linestyle = \"solid\", linewidth = 2, color = 'black')\n",
    "ax12.plot(coreset_sizes, np.log(np.nanmedian(klsym_parallel, axis = 0)[:, 0]), label = 'Random split',\n",
    "          linestyle = \"dashed\", linewidth = 2, color = 'dimgray')\n",
    "ax12.plot(coreset_sizes, np.log(np.nanmedian(klsym_parallel, axis = 0)[:, 1]), label = 'ML split',\n",
    "          linestyle = \"solid\", marker = \"o\", linewidth = 2, color = 'maroon')\n",
    "\n",
    "ax13.spines['bottom'].set_visible(False)\n",
    "ax13.xaxis.tick_top()\n",
    "ax13.tick_params(labeltop = False)\n",
    "ax14.spines['top'].set_visible(False)\n",
    "ax14.ticklabel_format(useOffset=False)\n",
    "\n",
    "ax12.set_xlabel(\"Coreset size\")\n",
    "ax14.set_xlabel(\"Coreset size\")\n",
    "\n",
    "fig.text(0.04, 0.5, 'Log KL', va='center', rotation='vertical')\n",
    "fig.text(0.494, 0.5, 'Seconds', va='center', rotation='vertical')\n",
    "\n",
    "d = .015\n",
    "\n",
    "kwargs = dict(transform=ax13.transAxes, color='k', clip_on=False)\n",
    "ax13.plot((-d, +d), (-d, +d), **kwargs)\n",
    "ax13.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=ax14.transAxes)\n",
    "ax14.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "ax14.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "fig.legend()\n",
    "fig.suptitle('Multivariate Gaussian Mixture')\n",
    "\n",
    "ax13.plot(coreset_sizes, np.nanmedian(time_sequential, axis = 0), label = 'Sequential',\n",
    "           linestyle = \"solid\", linewidth = 2, color = 'black')\n",
    "ax14.plot(coreset_sizes, np.nanmedian(time_parallel, axis = 0)[:, 0], label = 'Random split',\n",
    "          linestyle = \"dashed\", linewidth = 2, color = 'dimgray')\n",
    "ax14.plot(coreset_sizes, np.nanmedian(time_parallel, axis = 0)[:, 1], label = 'ML split',\n",
    "          linestyle = \"solid\", marker = \"o\", linewidth = 2, color = 'maroon')\n",
    "\n",
    "ax12.grid()\n",
    "ax13.grid()\n",
    "ax14.grid()\n",
    "\n",
    "# plt.savefig(\"../plots/multivariate_gaussian_mixture.eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyx\n",
    "c = pyx.canvas.canvas()\n",
    "c.insert(pyx.epsfile.epsfile(0, 0,\"../plots/multivariate_gaussian_mixture.eps\", align = \"tc\"))\n",
    "c.insert(pyx.epsfile.epsfile(0, 0, \"../plots/univariate_gaussian_mixture.eps\", align = \"bc\"))\n",
    "c.writeEPSfile(\"../plots/all_mixture.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "mu0 = np.array([3, 0]).reshape((-1, 1))\n",
    "mu1 = np.array([0, 0]).reshape((-1, 1))\n",
    "sigma0 = np.array([[1, 0.9,],\n",
    "                   [0.9, 1]])\n",
    "sigma1 = np.array([[1, -0.9,],\n",
    "                   [-0.9, 1]])\n",
    "\n",
    "full_means = [mu0, mu1]\n",
    "full_sigmas = [sigma0, sigma1]\n",
    "\n",
    "mixture_inds = np.random.choice([0, 1], size = 1000, replace = True)\n",
    "mixture = []\n",
    "\n",
    "for i in mixture_inds:\n",
    "    if i == 0:\n",
    "        mixture.append(np.random.multivariate_normal(mu0.flatten(), sigma0))\n",
    "    if i == 1:\n",
    "       mixture.append(np.random.multivariate_normal(mu1.flatten(), sigma1))\n",
    "\n",
    "mixture = np.array(mixture).reshape(-1, 2)\n",
    "\n",
    "plt.scatter(mixture[:, 0], mixture[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mixture\n",
    "\n",
    "# Sequential\n",
    "fkl_sequential = []\n",
    "bkl_sequential = []\n",
    "time_sequential = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(9),\n",
    "      \"S\": int(0.3 * len(x)),\n",
    "      \"log_likelihood_gradient\": None,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.7 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(9)}\n",
    "\n",
    "for k in range(1):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_sequential_k = []\n",
    "      bkl_sequential_k = []\n",
    "      time_sequential_k = []\n",
    "\n",
    "      w_seq = []\n",
    "\n",
    "      for i in [100, 200, 300]:\n",
    "            print(k, i)\n",
    "            start = time.time()\n",
    "            sbfw = SensitivityBasedFW(x)\n",
    "            w, I = sbfw.run(k = i, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "            time_sequential_k.append(time.time() - start)\n",
    "\n",
    "            # Calculate posterior approximation\n",
    "            gm = GaussianMixture(2)\n",
    "            gm.fit((w * mixture))\n",
    "            means = gm.means_\n",
    "            sigmas = gm.covariances_\n",
    "            ps = gm.weights_\n",
    "\n",
    "            means_inds = np.argsort(np.linalg.norm(means, axis = 1))\n",
    "            means = means[means_inds]\n",
    "            sigmas = sigmas[means_inds]\n",
    "            ps = ps[means_inds]\n",
    "\n",
    "            fkl = 0\n",
    "            bkl = 0\n",
    "            for j in range(2):\n",
    "                  fkl += mixture_kl_element(full_means[j], full_sigmas[j], means[:, j], sigmas[j], ps[j])\n",
    "                  bkl += mixture_kl_element(means[:, j], sigmas[j], full_means[j], full_sigmas[j], ps[j])\n",
    "\n",
    "            fkl_sequential_k.append(fkl)\n",
    "            bkl_sequential_k.append(bkl)\n",
    "\n",
    "            w_seq.append(w)\n",
    "\n",
    "      fkl_sequential.append(fkl_sequential_k)\n",
    "      bkl_sequential.append(bkl_sequential_k)\n",
    "      time_sequential.append(time_sequential_k)\n",
    "\n",
    "print(f\"FKL: {fkl_sequential}\")\n",
    "print(f\"BKL: {bkl_sequential}\")\n",
    "print(f\"Time: {time_sequential}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mixture\n",
    "\n",
    "# Parallel\n",
    "fkl_parallel = []\n",
    "bkl_parallel = []\n",
    "time_parallel = []\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_likelihood_start_value\": np.ones(9),\n",
    "      \"S\": int(0.3 * 0.1 * len(x)),\n",
    "      \"log_likelihood_gradient\": None,\n",
    "      \"approx\": \"MCMC\",\n",
    "      \"MCMC_subs_size\": int(0.1 * len(x)),\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(9)}\n",
    "\n",
    "for k in range(1):\n",
    "      np.random.seed(120 + k)\n",
    "      fkl_parallel_k = []\n",
    "      bkl_parallel_k = []\n",
    "      time_parallel_k = []\n",
    "\n",
    "      full_inds_i = []\n",
    "      output_i = []\n",
    "      w_i = []\n",
    "\n",
    "      for i in [100, 200, 300]:\n",
    "            print(f\"{k}: {i}\")\n",
    "            fkl_parallel_i = []\n",
    "            bkl_parallel_i = []\n",
    "            time_parallel_i = []\n",
    "            for ind, strat in enumerate([split_randomly, split_based_on_ML]):\n",
    "                  start = time.time()\n",
    "\n",
    "                  # Step 1: distribute\n",
    "                  if ind == 0:\n",
    "                        full_inds = strat(x)\n",
    "                  elif ind == 1:\n",
    "                        gm = GaussianMixture(2, n_init = 20)\n",
    "                        gm.fit(w * mixture)\n",
    "                        \n",
    "                        # Get probability estimates\n",
    "                        params = np.hstack((gm.weights_.flatten()[0], gm.means_.flatten()))\n",
    "                        log_liks = log_likelihood(params, mixture, None, None)\n",
    "                        probs = np.abs(log_liks) / np.sum(np.abs(log_liks))\n",
    "                        probs = probs.flatten()\n",
    "                        full_inds = distribute(probs)\n",
    "\n",
    "                  full_inds_i.append(full_inds)\n",
    "\n",
    "                  # Step 2: run\n",
    "                  w, output = parallelize(alg = SensitivityBasedFW, x = x, k = int(i // mp.cpu_count()), norm = \"2\", na = na, distributed_indices = full_inds)\n",
    "\n",
    "                  time_parallel_i.append(time.time() - start)\n",
    "\n",
    "                  # Calculate posterior approximation\n",
    "                  gm = GaussianMixture(2, n_init = 40)\n",
    "                  gm.fit((w * mixture))\n",
    "                  means = gm.means_\n",
    "                  sigmas = gm.covariances_\n",
    "                  ps = gm.weights_\n",
    "\n",
    "                  means_inds = np.argsort(np.linalg.norm(means, axis = 1))\n",
    "                  means = means[means_inds]\n",
    "                  sigmas = sigmas[means_inds]\n",
    "                  ps = ps[means_inds]\n",
    "\n",
    "                  fkl = 0\n",
    "                  bkl = 0\n",
    "                  for j in range(2):\n",
    "                        fkl += mixture_kl_element(full_means[j], full_sigmas[j], means[:, j], sigmas[j], ps[j])\n",
    "                        bkl += mixture_kl_element(means[:, j], sigmas[j], full_means[j], full_sigmas[j], ps[j])\n",
    "\n",
    "                  fkl_parallel_i.append(fkl)\n",
    "                  bkl_parallel_i.append(bkl)\n",
    "\n",
    "                  output_i.append(output)\n",
    "                  w_i.append(w)\n",
    "\n",
    "            fkl_parallel_k.append(fkl_parallel_i)\n",
    "            bkl_parallel_k.append(bkl_parallel_i)\n",
    "            time_parallel_k.append(time_parallel_i)\n",
    "\n",
    "      fkl_parallel.append(fkl_parallel_k)\n",
    "      bkl_parallel.append(bkl_parallel_k)\n",
    "      time_parallel.append(time_parallel_k)\n",
    "\n",
    "print(f\"FKL: {fkl_parallel}\")\n",
    "print(f\"BKL: {bkl_parallel}\")\n",
    "print(f\"Time: {time_parallel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coresets(mixture, w_seq[0], full_inds_i[0], output_i[0], w_i[0], 100, \"multivariate_gaussian_mixture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coresets(mixture, w_seq[1], full_inds_i[1], output_i[1], w_i[1], 200, \"multivariate_gaussian_mixture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coresets(mixture, w_seq[2], full_inds_i[2], output_i[2], w_i[2], 300, \"multivariate_gaussian_mixture\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
