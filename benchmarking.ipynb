{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "boxed-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ebc.sequential.non_iterative import SensitivityBasedIS\n",
    "from ebc.sequential.iterative_with_convexification import SensitivityBasedFW\n",
    "from ebc.sequential.iterative_no_convexification import SparseVI, GIGA, IHT\n",
    "from ebc.parallel.parallel_iterative_with_convexification import ParallelSensitivityBasedFW\n",
    "from ebc.gaussian import fisher_norm_under_true_gaussian_posterior, gaussian_multivariate_log_likelihood, gaussian_KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "violent-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "d = 20\n",
    "N = 1000\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Theta as in sparse_vi\n",
    "theta = np.random.multivariate_normal(mean = np.zeros(d), cov = np.identity(d))\n",
    "\n",
    "# x as in sparse_vi\n",
    "x = np.random.multivariate_normal(mean = theta, cov = np.identity(d), size = N)\n",
    "\n",
    "# Parameters\n",
    "sigma_0 = np.identity(d)\n",
    "sigma = np.identity(d)\n",
    "mu_0 = np.zeros(d).reshape(-1, 1)\n",
    "\n",
    "# Full Gaussian posterior\n",
    "sigma_full = np.linalg.inv(np.linalg.inv(sigma_0) + N * np.linalg.inv(sigma))\n",
    "mu_full =  sigma_full @ (np.linalg.inv(sigma_0) @ mu_0 + np.linalg.inv(sigma) @ np.sum(x, axis = 0).reshape(-1, 1))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "going-liberal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (1000, 20)\n",
      "mu: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x: {x.shape}\")\n",
    "print(f\"mu: {mu_0.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "applied-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(params, X, y, weights):\n",
    "    mu = params[:d].reshape(-1, 1)\n",
    "    sigma = np.diag(params[d:].reshape(-1, 1)[:, 0])\n",
    "    return np.diag(gaussian_multivariate_log_likelihood(X.T, mu, sigma)).reshape(-1, 1)\n",
    "\n",
    "# https://stats.stackexchange.com/questions/90134/gradient-of-multivariate-gaussian-log-likelihood\n",
    "def grad_log_likelihood(params, X, y, weights):\n",
    "    mu = params[:d].reshape(-1, 1)\n",
    "    sigma = np.diag(params[d:].reshape(-1, 1)[:, 0])\n",
    "    return (-np.linalg.inv(sigma) @ (X.T - mu)).reshape(-1, X.shape[1])\n",
    "\n",
    "def log_posterior(params, X, y, weights):\n",
    "    return weights.T @ log_likelihood(params, X, y, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupied-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_gram_matrix = fisher_norm_under_true_gaussian_posterior(x.T, x.T, mu_0, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lightweight-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_points(points, indices, w):\n",
    "    pca = PCA(n_components = 2)\n",
    "    vecs = pca.fit_transform(points)\n",
    "    plt.scatter(vecs[indices, 0], vecs[indices, 1], \n",
    "                  s = w.flatten()[indices] * 50, alpha = 0.5)\n",
    "    vecs = np.delete(vecs, indices, axis = 0)\n",
    "    plt.scatter(vecs[:, 0], vecs[:, 1], alpha = 0.5, label = \"NOT in coreset\")\n",
    "    plt.title(\"Points\")\n",
    "    plt.ylabel(\"PCA2\")\n",
    "    plt.xlabel(\"PCA1\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "def plot_results(fkl, bkl, points, indices, w):\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (20, 5))\n",
    "    ax[0].plot(fkl)\n",
    "    ax[0].set_title(\"FKL\")\n",
    "    ax[0].set_ylabel(\"FKL\")\n",
    "    ax[0].set_xlabel(\"Coreset Size\")\n",
    "    ax[0].grid()\n",
    "    \n",
    "    ax[1].plot(fkl)\n",
    "    ax[1].set_title(\"BKL\")\n",
    "    ax[1].set_ylabel(\"BKL\")\n",
    "    ax[1].set_xlabel(\"Coreset Size\")\n",
    "    ax[1].grid()\n",
    "    \n",
    "    pca = PCA(n_components = 2)\n",
    "    vecs = pca.fit_transform(points)\n",
    "    ax[2].scatter(vecs[indices, 0], vecs[indices, 1], \n",
    "                  s = w.flatten()[indices] * 50, alpha = 0.5)\n",
    "    vecs = np.delete(vecs, indices, axis = 0)\n",
    "    ax[2].scatter(vecs[:, 0], vecs[:, 1], alpha = 0.5, label = \"NOT in coreset\")\n",
    "    ax[2].set_title(\"Points\")\n",
    "    ax[2].set_ylabel(\"PCA2\")\n",
    "    ax[2].set_xlabel(\"PCA1\")\n",
    "    ax[2].grid()\n",
    "    ax[2].legend()\n",
    "    \n",
    "    #for ind in indices:\n",
    "    #    ax[2].annotate(round(w.flatten()[ind]), (vecs[ind, 0], vecs[ind, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-royal",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-going",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "color-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1 10.29118800163269\n",
      "step2 1.621246337890625e-05\n",
      "step4 0.0006108283996582031\n",
      "===\n",
      "step1 9.711379051208496\n",
      "step2 8.821487426757812e-06\n",
      "step4 0.0005528926849365234\n",
      "===\n",
      "step1 9.483436107635498\n",
      "step2 8.821487426757812e-06\n",
      "step4 0.00044274330139160156\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "sbis = SensitivityBasedIS(x)\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "  \"log_likelihood_start_value\": np.ones(2 * d),\n",
    "  \"S\": 150,\n",
    "  \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "  \"approx\": \"Laplace\",\n",
    "  \"MCMC_subs_size\": 100}\n",
    "\n",
    "w, I = sbis.run(k = 20, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = sbis.run(k = 200, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = sbis.run(k = 500, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "concerned-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1 9.673496961593628\n",
      "s2 0.007975339889526367\n",
      "s3 0.000164031982421875\n",
      "s4 0.013739347457885742\n",
      "===\n",
      "step1 9.896965265274048\n",
      "s2 0.10611939430236816\n",
      "s3 0.003424406051635742\n",
      "s4 0.2059619426727295\n",
      "===\n",
      "step1 9.864297866821289\n",
      "s2 0.23502659797668457\n",
      "s3 0.0077898502349853516\n",
      "s4 0.442737340927124\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "sbfw = SensitivityBasedFW(x)\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "  \"log_likelihood_start_value\": np.ones(2 * d),\n",
    "  \"S\": 150,\n",
    "  \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "  \"approx\": \"Laplace\",\n",
    "  \"MCMC_subs_size\": 100}\n",
    "\n",
    "w, I = sbfw.run(k = 20, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = sbfw.run(k = 200, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = sbfw.run(k = 500, likelihood_gram_matrix = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "psychological-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 3.814697265625e-06\n",
      "s2 0.005140542984008789\n",
      "s3 0.0003466606140136719\n",
      "s4 0.34872913360595703\n",
      "===\n",
      "s1 7.152557373046875e-07\n",
      "s2 0.02663564682006836\n",
      "s3 0.002057313919067383\n",
      "s4 3.0166895389556885\n",
      "===\n",
      "s1 0.0\n",
      "s2 0.06612658500671387\n",
      "s3 0.005747795104980469\n",
      "s4 7.762170791625977\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "def log_posterior(params, X, y, weights):\n",
    "        return np.sum(log_likelihood(params, X, y, weights))\n",
    "\n",
    "svi = SparseVI(x)\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "      \"log_posterior\": log_posterior,\n",
    "      \"log_posterior_start_value\": np.ones(2 * d),\n",
    "      \"S\": 150,\n",
    "      \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "      \"approx\": \"MCMC\"}\n",
    "\n",
    "w, I = svi.run(k = 20, likelihood_gram_matrix = likelihood_gram_matrix, \n",
    "               norm_attributes = na, T = 100, gamma_func = lambda x : 1 / x)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = svi.run(k = 200, likelihood_gram_matrix = likelihood_gram_matrix, \n",
    "               norm_attributes = na, T = 100, gamma_func = lambda x : 1 / x)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = svi.run(k = 500, likelihood_gram_matrix = likelihood_gram_matrix, \n",
    "               norm_attributes = na, T = 100, gamma_func = lambda x : 1 / x)\n",
    "\n",
    "print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunrise-lawrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 9.744696855545044\n",
      "s2 0.023221969604492188\n",
      "s3 0.0008225440979003906\n",
      "s4 0.00639796257019043\n",
      "===\n",
      "s1 9.528355121612549\n",
      "s2 0.232161283493042\n",
      "s3 0.008537530899047852\n",
      "s4 0.061745643615722656\n",
      "===\n",
      "s1 9.632551193237305\n",
      "s2 0.5769641399383545\n",
      "s3 0.02127385139465332\n",
      "s4 0.15732550621032715\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "giga = GIGA(x)\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "  \"log_likelihood_start_value\": np.ones(2 * d),\n",
    "  \"S\": 150,\n",
    "  \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "  \"approx\": \"Laplace\",\n",
    "  \"MCMC_subs_size\": 100}\n",
    "\n",
    "w, I = giga.run(k = 20, likelihood_vectors = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = giga.run(k = 200, likelihood_vectors = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = giga.run(k = 500, likelihood_vectors = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "herbal-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 9.879639863967896\n",
      "s2 0.20624256134033203\n",
      "s3 0.2554507255554199\n",
      "s4 0.3558673858642578\n",
      "===\n",
      "s1 9.679489135742188\n",
      "s2 0.20745277404785156\n",
      "s3 0.33858799934387207\n",
      "s4 0.3341825008392334\n",
      "===\n",
      "s1 9.948122024536133\n",
      "s2 0.20511436462402344\n",
      "s3 0.4359571933746338\n",
      "s4 0.30448246002197266\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "iht = IHT(x)\n",
    "\n",
    "na = {\"log_likelihood\": log_likelihood,\n",
    "  \"log_likelihood_start_value\": np.ones(2 * d),\n",
    "  \"S\": 150,\n",
    "  \"log_likelihood_gradient\": grad_log_likelihood,\n",
    "  \"approx\": \"Laplace\",\n",
    "  \"MCMC_subs_size\": 100}\n",
    "\n",
    "w, I = iht.run(k = 20, likelihood_vectors = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = iht.run(k = 200, likelihood_vectors = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')\n",
    "\n",
    "w, I = iht.run(k = 500, likelihood_vectors = None, norm = \"2\", norm_attributes = na)\n",
    "\n",
    "print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-communications",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
